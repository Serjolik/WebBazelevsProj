# Welcome to Bazelevs studio

In this project, we used "Stable diffusion" and "ChatGPT" to create new characters and storyboards with them.

<img src="https://for-press.ru/wp-content/uploads/2023/03/unnamed.png" width="512" height="256">


To implement the interface, we used "C#" and "Js".

<html>
 <head>
  <meta charset="utf-8">
 </head>
 <body>
  <p>
    <img src="https://pnggallery.com/wp-content/uploads/javascript-logo-04.png" width="120" height="120">
    <img src="https://github.com/Serjolik/WebBazilevsProj/assets/109044567/0b0e81cb-9ae6-496e-82ac-e9ac950a2dc7" width="200" height="120">
  </p>
 </body>
</html>


## About us

<h4>
   Hi, We're team Clowns.rar.
</h4>

<h4>
    Our team leader: Alexandra Igitova
 </h4>
  <h4>
  Our fullstack developer: Sergey Vysotskiy - https://github.com/Serjolik
   </h4>
   <h4>
     Our ML: Kirill Ilyushkin - https://github.com/Jagerishere
    </h4>
<h4>    
Our Data analyst: Vladislav Malyuzhenets - https://github.com/vladmln
</h4>
 
   
  
 
 
## About project
In this project, we implemented an interface for generating a description of a character specified by the user and creating images in StableDiffusion based on promt obtained using ChatGPT. It is also possible to get a storyboard.

## Our architecture

<img src="https://github.com/Serjolik/WebBazilevsProj/assets/109044567/5180514d-c51e-4a09-b749-2e5011919d0c" width="1024" height="512">

## Stable Diffusion v2
Stable Diffusion v2 refers to a specific configuration of the model architecture that uses a downsampling-factor 8 autoencoder with an 865M UNet and OpenCLIP ViT-H/14 text encoder for the diffusion model. The SD 2-v model produces 768x768 px outputs.

Evaluations with different classifier-free guidance scales (1.5, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0) and 50 DDIM sampling steps show the relative improvements of the checkpoints:

<img src="https://github.com/Stability-AI/stablediffusion/blob/main/assets/model-variants.jpg?raw=true" width="512" height="256">

## 


